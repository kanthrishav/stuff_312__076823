import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
from torchvision import datasets, transforms

import numpy as np
import random

# For metrics
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, log_loss, roc_auc_score
from sklearn.preprocessing import label_binarize

# For Plotly visualization
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# -------------------------------
# Define a Convolutional Neural Network
# -------------------------------
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        # First convolution: 1 input channel, 32 output channels, kernel 3x3 with padding for same output size
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        # Second convolution: from 32 to 64 channels
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        # Pooling layer reduces each spatial dimension by 2
        self.pool = nn.MaxPool2d(2, 2)
        # Fully connected layers: after pooling the image becomes 64 x 14 x 14 (MNIST images are 28x28)
        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST

    def forward(self, x):
        # Apply two conv layers with ReLU activation
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        # Pooling layer
        x = self.pool(x)
        # Flatten the tensor for fully connected layers
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)  # Note: no softmax here because CrossEntropyLoss expects raw logits
        return x

# -------------------------------
# Training and Evaluation Functions
# -------------------------------
def train(model, device, train_loader, optimizer, criterion):
    model.train()
    running_loss = 0.0
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()  # zero the parameter gradients
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * data.size(0)
    return running_loss / len(train_loader.dataset)

def evaluate(model, device, loader, criterion):
    model.eval()
    test_loss = 0.0
    all_preds = []
    all_targets = []
    all_probs = []
    with torch.no_grad():
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            test_loss += loss.item() * data.size(0)
            probs = F.softmax(output, dim=1)
            preds = output.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    avg_loss = test_loss / len(loader.dataset)
    return avg_loss, np.array(all_preds), np.array(all_targets), np.array(all_probs)

# -------------------------------
# Main Function
# -------------------------------
def main():
    # Check device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Data preprocessing and loading
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # mean and std for MNIST
    ])
    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # Initialize model, loss, optimizer and scheduler
    model = CNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

    # Training loop
    epochs = 10
    for epoch in range(1, epochs + 1):
        train_loss = train(model, device, train_loader, optimizer, criterion)
        val_loss, _, _, _ = evaluate(model, device, test_loader, criterion)
        scheduler.step(val_loss)
        print(f"Epoch {epoch}/{epochs} - Training Loss: {train_loss:.6f} - Validation Loss: {val_loss:.6f}")

    # Evaluation on test set
    test_loss, preds, targets, probs = evaluate(model, device, test_loader, criterion)

    # Compute Metrics
    accuracy = accuracy_score(targets, preds)
    cm = confusion_matrix(targets, preds)
    precision = precision_score(targets, preds, average='macro')
    recall = recall_score(targets, preds, average='macro')
    f1 = f1_score(targets, preds, average='macro')
    logloss = log_loss(targets, probs)
    # For multiclass AUC-ROC we binarize the labels
    targets_bin = label_binarize(targets, classes=range(10))
    auc_roc = roc_auc_score(targets_bin, probs, average='macro', multi_class='ovr')

    print("\nTest Metrics:")
    print(f"Accuracy: {accuracy:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Precision (macro): {precision:.4f}")
    print(f"Recall (macro): {recall:.4f}")
    print(f"F1 Score (macro): {f1:.4f}")
    print(f"Log Loss: {logloss:.4f}")
    print(f"AUC-ROC (macro): {auc_roc:.4f}")

    # -------------------------------
    # Visualization with Plotly
    # -------------------------------
    # Sample 16 random indices from the test dataset
    indices = random.sample(range(len(test_dataset)), 16)
    # Create subplot titles with predicted and true labels
    subplot_titles = []
    for ind in indices:
        # Note: test_dataset[ind] returns (image, label)
        _, true_label = test_dataset[ind]
        pred_label = preds[ind]
        subplot_titles.append(f"Pred: {pred_label}, True: {true_label}")

    # Create a 4x4 subplot grid
    fig = make_subplots(rows=4, cols=4, subplot_titles=subplot_titles)
    # Determine text size as 25% of image size (MNIST images are 28x28 -> 7 px)
    text_size = 7

    # Add each image to the subplot grid
    for i, ind in enumerate(indices):
        row = i // 4 + 1
        col = i % 4 + 1
        # Get the image tensor and label; unnormalize the image
        img_tensor, _ = test_dataset[ind]
        img = img_tensor * 0.3081 + 0.1307  # undo normalization
        img_np = img.squeeze().cpu().numpy()  # shape: (28, 28)
        # Add the image as a trace; go.Image accepts the 2D array for grayscale
        fig.add_trace(go.Image(z=img_np), row=row, col=col)

    # Update the subplot title font sizes to be 25% of image size
    for annotation in fig.layout.annotations:
        annotation.font.size = text_size

    fig.update_layout(height=800, width=800, title_text="MNIST Predictions (16 Random Samples)")
    # Save the figure to an HTML file; do not display the plot
    fig.write_html("mnist_predictions.html")
    print("\nPlot saved to 'mnist_predictions.html'.")

if __name__ == '__main__':
    main()
