import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader
import torchvision
from torchvision import transforms, datasets, models

import numpy as np
import random

# For metrics
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, log_loss, roc_auc_score
from sklearn.preprocessing import label_binarize

# For Plotly visualization
import plotly.graph_objects as go
from plotly.subplots import make_subplots

def get_resnet18_cifar100():
    """
    Returns a ResNet-18 model modified for CIFAR-100.
    - The first convolution is changed to a 3x3 kernel with stride 1 and padding 1,
      which better suits the 32x32 images.
    - The max pooling layer is replaced by an identity operation.
    - The fully connected layer is replaced to output 100 classes.
    """
    model = models.resnet18(pretrained=False)
    # Modify first conv layer to reduce excessive downsampling for small images.
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
    model.maxpool = nn.Identity()  # Remove max pooling layer
    # Replace the fully connected layer to match CIFAR-100 classes
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 100)
    return model

def train(model, device, train_loader, optimizer, criterion):
    model.train()
    running_loss = 0.0
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
    return running_loss / len(train_loader.dataset)

def evaluate(model, device, loader, criterion):
    model.eval()
    test_loss = 0.0
    all_preds = []
    all_targets = []
    all_probs = []
    with torch.no_grad():
        for inputs, targets in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            test_loss += loss.item() * inputs.size(0)
            probs = F.softmax(outputs, dim=1)
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    avg_loss = test_loss / len(loader.dataset)
    return avg_loss, np.array(all_preds), np.array(all_targets), np.array(all_probs)

def unnormalize(img, mean, std):
    """
    Reverts the normalization for an image tensor.
    Converts the image tensor from normalized values back to [0,255] as a numpy array.
    """
    img = img.clone().cpu().numpy()
    for i in range(3):
        img[i] = img[i] * std[i] + mean[i]
    img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)
    img = np.clip(img, 0, 1)
    img = (img * 255).astype(np.uint8)
    return img

def main():
    # --- Device configuration ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Using device:", device)
    
    # --- Data transforms and loading ---
    # CIFAR-100 normalization values
    cifar100_mean = (0.5071, 0.4867, 0.4408)
    cifar100_std = (0.2675, 0.2565, 0.2761)
    
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(cifar100_mean, cifar100_std),
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(cifar100_mean, cifar100_std),
    ])
    
    train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)
    test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)
    
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)
    
    # --- Model, Loss, Optimizer, and Scheduler ---
    model = get_resnet18_cifar100().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)
    
    # --- Training Loop ---
    num_epochs = 20
    for epoch in range(1, num_epochs+1):
        train_loss = train(model, device, train_loader, optimizer, criterion)
        val_loss, _, _, _ = evaluate(model, device, test_loader, criterion)
        scheduler.step(val_loss)
        print(f"Epoch {epoch}/{num_epochs} - Training Loss: {train_loss:.6f} - Validation Loss: {val_loss:.6f}")
    
    # --- Evaluation on Test Set ---
    test_loss, preds, targets, probs = evaluate(model, device, test_loader, criterion)
    
    # Compute various metrics
    accuracy = accuracy_score(targets, preds)
    cm = confusion_matrix(targets, preds)
    precision = precision_score(targets, preds, average='macro', zero_division=0)
    recall = recall_score(targets, preds, average='macro', zero_division=0)
    f1 = f1_score(targets, preds, average='macro', zero_division=0)
    logloss = log_loss(targets, probs)
    # Binarize targets for multi-class AUC-ROC calculation
    targets_bin = label_binarize(targets, classes=list(range(100)))
    auc_roc = roc_auc_score(targets_bin, probs, average='macro', multi_class='ovr')
    
    print("\nTest Metrics:")
    print(f"Accuracy: {accuracy:.4f}")
    print("Confusion Matrix:")
    print(cm)
    print(f"Precision (macro): {precision:.4f}")
    print(f"Recall (macro): {recall:.4f}")
    print(f"F1 Score (macro): {f1:.4f}")
    print(f"Log Loss: {logloss:.4f}")
    print(f"AUC-ROC (macro): {auc_roc:.4f}")
    
    # --- Visualization with Plotly ---
    # Randomly select 16 indices from the test dataset
    indices = random.sample(range(len(test_dataset)), 16)
    subplot_titles = []
    for ind in indices:
        true_label = test_dataset.targets[ind]
        pred_label = preds[ind]  # test_loader was not shuffled so order is preserved
        class_name_true = test_dataset.classes[true_label]
        class_name_pred = test_dataset.classes[pred_label]
        subplot_titles.append(f"Pred: {class_name_pred}, True: {class_name_true}")
    
    # Create a 4x4 grid of subplots with the titles
    fig = make_subplots(rows=4, cols=4, subplot_titles=subplot_titles)
    
    # Calculate text size as 25% of the image size (32x32, so 25% = 8 pixels)
    text_size = int(0.25 * 32)
    
    # Add each selected image to the grid after unnormalizing
    for i, ind in enumerate(indices):
        row = i // 4 + 1
        col = i % 4 + 1
        img_tensor, _ = test_dataset[ind]
        img = unnormalize(img_tensor, cifar100_mean, cifar100_std)
        fig.add_trace(go.Image(z=img), row=row, col=col)
    
    # Adjust annotation font sizes (subplot titles) to be 25% of image size
    for annotation in fig.layout.annotations:
        annotation.font.size = text_size
    
    fig.update_layout(height=800, width=800, title_text="CIFAR-100 Predictions (16 Random Samples)")
    # Save the plot to an HTML file; do not display it
    fig.write_html("cifar100_predictions.html")
    print("\nVisualization saved to 'cifar100_predictions.html'.")
    
if __name__ == '__main__':
    main()
